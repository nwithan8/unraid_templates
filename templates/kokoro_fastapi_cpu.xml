<?xml version="1.0"?>
<Container version="2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="https://raw.githubusercontent.com/nwithan8/unraid_templates/main/templates/template_schema.xsd template_schema.xsd">
    <Name>Kokoro FastAPI - CPU</Name>
    <Repository>ghcr.io/remsky/kokoro-fastapi-cpu:latest</Repository>
    <Registry>ghcr.io/remsky/kokoro-fastapi-cpu</Registry>
    <Branch>
        <Tag>latest</Tag>
        <TagDescription>Latest stable release</TagDescription>
    </Branch>
    <Network>bridge</Network>
    <WebUI>http://[IP]:[PORT:8880]/</WebUI>
    <Privileged>false</Privileged>
    <Support>https://github.com/remsky/Kokoro-FastAPI/issues</Support>
    <Project>https://github.com/remsky/Kokoro-FastAPI</Project>
    <Overview>
        Dockerized FastAPI wrapper for Kokoro-82M text-to-speech model w/CPU ONNX and NVIDIA GPU PyTorch support, handling, and auto-stitching. &#xD;
        [br]
        This is a version meant for running on CPUs. It is not recommended to run this on a CPU unless you have a very powerful CPU, as it will be slow. If you have a GPU, please use the GPU version of this container.
    </Overview>
    <Beta>False</Beta>
    <Category>AI: Productivity: Tools: Other: Status:Stable</Category>
    <ExtraSearchTerms>ai docker fastapi kokoro text-to-speech tts speech synthesis voice generation onnx cpu gpu nvidia</ExtraSearchTerms>
    <Icon>https://raw.githubusercontent.com/nwithan8/unraid_templates/master/images/kokoro-fastapi-icon.png</Icon>
    <Banner>https://raw.githubusercontent.com/remsky/Kokoro-FastAPI/master/githubbanner.png</Banner>
    <TemplateURL>https://raw.githubusercontent.com/nwithan8/unraid_templates/main/templates/kokoro_fastapi_cpu.xml</TemplateURL>
    <Screenshot>https://raw.githubusercontent.com/remsky/Kokoro-FastAPI/master/assets/docs-screenshot.png</Screenshot>
    <Screenshot>https://raw.githubusercontent.com/remsky/Kokoro-FastAPI/master/assets/webui-screenshot.png</Screenshot>
    <Maintainer>
        <WebPage>https://github.com/nwithan8</WebPage>
    </Maintainer>
    <Changes>
        ### 2025-11-07

        Update environmental variables

        ### 2025-04-25

        Initial release
    </Changes>
    <Config Name="Web UI Port" Target="8880" Default="8880" Mode="tcp" Description="Container Port: 8880" Type="Port" Display="always-hide" Required="true" Mask="false">8880</Config>
    <Config Name="App Data" Target="/app/api" Default="/mnt/user/appdata/kokoro-fastapi/data" Description="Path to the app data folder" Type="Path" Display="advanced-hide" Required="true" Mask="false">/mnt/user/appdata/kokoro-fastapi/data</Config>
    <Config Name="Python Path" Target="PYTHONPATH" Default="/app:/app/api" Description="Python path environment variable" Type="Variable" Display="advanced-hide" Required="true" Mask="false">/app:/app/api</Config>
    <Config Name="ONNX Optimization - Thread Count" Target="ONNX_NUM_THREADS" Default="8" Description="Number of threads to use for ONNX model inference" Type="Variable" Display="advanced-hide" Required="true" Mask="false">8</Config>
    <Config Name="ONNX Optimization - Inter Op Thread Count" Target="ONNX_INTER_OP_THREADS" Default="4" Description="ONNX inter operation thread count" Type="Variable" Display="advanced-hide" Required="true" Mask="false">4</Config>
    <Config Name="ONNX Optimization - Execution Mode" Target="ONNX_EXECUTION_MODE" Default="parallel" Description="ONNX execution mode" Type="Variable" Display="advanced-hide" Required="true" Mask="false">parallel</Config>
    <Config Name="ONNX Optimization - Optimization Level" Target="ONNX_OPTIMIZATION_LEVEL" Default="all" Description="ONNX optimization level" Type="Variable" Display="advanced-hide" Required="true" Mask="false">all</Config>
    <Config Name="ONNX Optimization - Memory Pattern" Target="ONNX_MEMORY_PATTERN" Default="true" Description="Enable ONNX memory pattern optimization" Type="Variable" Display="advanced-hide" Required="true" Mask="false">true</Config>
    <Config Name="ONNX Optimization - Arena Extend Strategy" Target="ONNX_ARENA_EXTEND_STRATEGY" Default="kNextPowerOfTwo" Description="ONNX arena extend strategy" Type="Variable" Display="advanced-hide" Required="true" Mask="false">kNextPowerOfTwo</Config>
    <Config Name="Log Level" Target="API_LOG_LEVEL" Default="DEBUG" Description="Logging level for the API" Type="Variable" Display="advanced-hide" Required="true" Mask="false">DEBUG</Config>
</Container>
